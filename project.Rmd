---
title: "Prediction"
author: "Andrea Schioppa"
output:
  html_document:
    keep_md: yes
---
We build a Machine Learning algorithm to predict
how well participants in a weight lifting experiment did. The data is available from the website (http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset). We assume that the data is downloaded in the current directory in the file 'pml-training.csv'.

#Cleaning the Data

We load required libraries.
```{r libraries, cache = TRUE}
library(ggplot2);
library(caret);
```

We load the training data.

```{r load, cache=TRUE}
data.train <- read.csv('pml-training.csv', header=TRUE);
```

Remove first column which is just the row number. Some predictors consist of a large
fraction of `NA`s and so we remove them.

```{r clean1, cache=TRUE}
data.train <- data.train[,-1];

na.predictors <- c();

for(i in 1:length(names(data.train))) {
    if(mean(is.na(data.train[,i]))>0.90)
        na.predictors <- c(na.predictors,i);
}

data.train <- data.train[,-na.predictors];
```

The predictor `cvtd_timestamp`, is a kind of time stamp which has been read as a character,
and we convert it to a numeric format using the `POSIXct` standard.

```{r clean2, cache = TRUE}
data.train$cvtd_timestamp <- strptime(data.train$cvtd_timestamp, format='%d/%m/%Y %H:%M');
data.train$cvtd_timestamp <- as.numeric(as.POSIXct(data.train$cvtd_timestamp));
```

There are also other predictors which contain many missing values. They were not
eliminated before because they show as factors; we now remove them:

```{r clean3, cache = TRUE}

na.predictors <- c();

for(i in 2:(length(names(data.train))-1)) {
    if(class(data.train[,i])=='factor') {
    if(mean(as.character(data.train[,i])=="")>0.90) {
        na.predictors <- c(na.predictors,i);
    }
   }
}

data.train <- data.train[,-na.predictors];
```

We finally convert to `numeric` predictors that were read as `integers`.

```{r clean4, cache = TRUE}
for(i in 1:length(names(data.train))) {
    if(class(data.train[,i])=='integer') {
        data.train[,i] <- as.numeric(data.train[,i]);
    }
}
```

# Further Choice of Predictors

The cleaned data frame `data.train` contains now 59 columns, 58 of which are predictors, and the last
one is the variable `classe` which has to be predicted. We now split the data set into a train and test
part. Note that as we are going to fit a Random Forest, this is not necessary, but we do this to
illustrate the model

```{r split, cache = TRUE, message = FALSE}
set.seed(125);
library(caret);

split.indx <- createDataPartition(data.train$classe, p = 0.8, list = FALSE);
data.test <- data.train[-split.indx, ]
data.train <- data.train[split.indx, ]
```

The variables `cvtd_timestamp` and `raw_timestamp_part_1` are almost perfectly correlated.

```{r stamp_corr, cache = TRUE}
cor(data.train$cvtd_timestamp, data.train$raw_timestamp_part_1)
```

```{r}
library(caret)
timestamps <- data.frame(cvtd = data.train$cvtd_timestamp, rw1 = data.train$raw_timestamp_part_1);
preproc.tsmp <- preProcess(timestamps, method = c('center', 'scale'));
timestamps <- predict(preproc.tsmp, timestamps)
with(timestamps, plot(cvtd, rw1));
```

Also a plot shows that `raw_timestamp_part_2` is rather homogeneous among the different classes.

```{r}
tmsp.plot <- ggplot(data.train, aes(x=raw_timestamp_part_2, fill=classe, y = ..count..));
tmsp.plot <- tmsp.plot
tmsp.plot + geom_histogram() + facet_wrap(~classe);
```

Overall, the timestamps are variables which to do not seem to have predictive value, so we
remove them.

```{r stamp_rem, cache = TRUE}
toremove <- c('raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp');
data.train <- data.train[,-which(names(data.train) %in% toremove)];
data.test <- data.test[,-which(names(data.test) %in% toremove)];
```

# Model Choice and Training

We now fit a Random Forest. We have also tried
other models using `method=lda`, `method=gbm`, `method=svmLinear`, but the Random Forest seems to give the best results. 
Note that, as we use a Random Forest, there is no need for explicitly invoking cross-validation
via setting `TrControl` in this model. 
As it takes some hours to train this model, cross-validation would also make the code slower.
As Fitting the model is time-consuming, we save the model to an external file.
```{r train, cache = TRUE, eval = FALSE}
mod.rf <- train(classe ~ ., method = 'rf', prox = TRUE, data = data.train)
save(mod.rf, file='model.RData')
```

We summarize the model.

```{r}
load('model.RData')
mod.rf
```

The following plot shows how the model used accuracy to select the optimal number of trees.

```{r}
plot(mod.rf, main='Accuracy vs. Number or trees')
```

We compute the confusion Matrix to show Accuracy and Kappa on the test set to compare with the one predicted from the model.

```{r}
library(caret)
pred.test <- predict(mod.rf, newdata = data.test)
tab <- confusionMatrix(data.test$classe, pred.test)
tab
```